{"cells":[{"metadata":{"_uuid":"b213320a-08d8-4235-8dfd-1d03df2dede1","_cell_guid":"4190f27a-169b-48ce-8382-f2b966dc2d05","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd\nimport cv2, gc\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.metrics import fbeta_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.utils import shuffle\nfrom keras.models import Sequential\nfrom keras.layers import Dense, BatchNormalization, Flatten\nfrom keras.applications.vgg19 import VGG19\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow import keras\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"44de38f8-5106-4c40-a28f-6a0f7eed8fe3","_cell_guid":"235cc4b5-c0ee-4b75-b591-fc7f9843f979","trusted":true},"cell_type":"code","source":"input_size = 128\nepoch = 20\nbatch_size = 128\ninput_shape = (input_size, input_size, 3)\npath = '/kaggle/input/planets-dataset/planet/planet/'","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"18b86af5-e296-45f7-adc3-5689303f21f2","_cell_guid":"74f45f52-f940-49d0-9891-22c01f67f278","trusted":true},"cell_type":"code","source":"gc.collect()\ntrain_classes = pd.read_csv(f'{path}train_classes.csv')\ntrain_classes = shuffle(train_classes, random_state=0)\nsample_submission = pd.read_csv(f'{path}sample_submission.csv')\ntrad_sample_df = sample_submission[sample_submission.image_name.str.contains('file_')].copy()\nsample_submission = sample_submission[sample_submission.image_name.str.contains('test_')]","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s = train_classes.tags.str.split(' ').explode()\nlb = MultiLabelBinarizer()\nencoded = lb.fit_transform(s.values[:, None])\none_hot_df = pd.DataFrame(encoded.tolist(), columns=np.ravel(lb.classes_), dtype='int') \\\n                .groupby(s.index) \\\n                .sum()\none_hot_df['image_name'] = train_classes[\"image_name\"].apply(lambda fn: fn+\".jpg\")\ncols = ['image_name'] + list(np.ravel(lb.classes_))\ntrain_classes = one_hot_df[cols].copy()\ndel one_hot_df, s, encoded, lb\ntrad_sample_df['image_name'] = trad_sample_df[\"image_name\"].apply(lambda fn: fn+\".jpg\")\nsample_submission['image_name'] = sample_submission[\"image_name\"].apply(lambda fn: fn+\".jpg\")","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"d73c8b36-e9c8-4ea3-b25f-73937261f46f","_cell_guid":"54ea9955-d8b3-440b-a21d-c13b8487751f","trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True,\n                             zoom_range=0.5, rotation_range=90,\n                             rescale=1./255.)","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"3754ea10-ccc6-4191-bcd6-3edac58aeba3","_cell_guid":"a7fe1aab-779a-4f80-a34e-cd023f9018a2","trusted":true},"cell_type":"code","source":"def VGG19_Amazon_Model(input_shape=input_shape):\n    gc.collect()\n    base_model = VGG19(include_top=False, weights='imagenet',\n                       input_shape=input_shape)\n    model = Sequential()\n    model.add(BatchNormalization(input_shape=input_shape))\n    model.add(base_model)\n    model.add(Flatten())\n    model.add(Dense(17, activation='sigmoid'))\n   \n    return model\n\n\ndef return_model_name(k):\n    return '/kaggle/working/model_'+str(k)+'.h5'\n\n\ndef train_model(df, k=5):\n    gc.collect()\n    model = VGG19_Amazon_Model()\n    kf = KFold(n_splits=k, random_state=1, shuffle=True)\n    fold = 1\n\n    for train_index, val_index in kf.split(df.image_name):\n        \n        training_data = df.iloc[train_index]\n        validation_data = df.iloc[val_index]\n        \n        train_generator=datagen.flow_from_dataframe(\n                                            dataframe=training_data, directory=f'{path}/train-jpg/',\n                                            x_col=\"image_name\", y_col=cols[1:], batch_size=batch_size,\n                                            seed=42, shuffle=True, class_mode=\"raw\",\n                                            target_size=(input_size, input_size))\n        \n        val_generator=datagen.flow_from_dataframe(\n                                            dataframe=validation_data, directory=f'{path}/train-jpg/',\n                                            x_col=\"image_name\", y_col=cols[1:], batch_size=batch_size,\n                                            seed=42, shuffle=True, class_mode=\"raw\",\n                                            target_size=(input_size, input_size))\n        \n        STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n        STEP_SIZE_VAL = val_generator.n//val_generator.batch_size\n        \n        opt = Adam(lr=0.0001)\n        model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n\n        callback = [EarlyStopping(monitor='val_accuracy', patience=4, verbose=1),\n                    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2,\n                                   cooldown=2, verbose=1),\n                    ModelCheckpoint(return_model_name(fold), monitor='val_accuracy', \n                                    verbose=1, save_best_only=True, mode='max')]\n        history = model.fit_generator(train_generator, \n                                      validation_data=val_generator,\n                                      callbacks=callback, verbose=1, epochs=epoch) \n        \n        #pred_val = model.predict_generator(val_generator, verbose=1)\n        fold += 1\n        \n    return val_generator\n\n\ndef predict_model(test_gen, k=5, batch_size=batch_size):\n    model = VGG19_Amazon_Model()\n    full_test = []\n\n    for nfold in range(1,k+1):\n        model.load_weights(filepath=return_model_name(nfold))\n        p_test = model.predict_generator(test_gen, verbose=1)\n        full_test.append(p_test)\n    \n    result = np.array(full_test[0])\n    for i in range(1, k):\n        result += np.array(full_test[i])\n    result = result / k\n    \n    result_bool = (result > 0.18)\n    \n    return result_bool.astype(int)","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"90635d17-062a-45c4-8ee6-339110ed4104","_cell_guid":"7ab5c811-b305-4c56-84c9-39487052b93c","trusted":true},"cell_type":"code","source":"val_generator = train_model(train_classes)\ngc.collect()","execution_count":7,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n80142336/80134624 [==============================] - 0s 0us/step\nFound 32383 validated image filenames.\nFound 8096 validated image filenames.\nEpoch 1/20\n253/253 [==============================] - ETA: 0s - loss: 0.1486 - accuracy: 0.0972\nEpoch 00001: val_accuracy improved from -inf to 0.12932, saving model to /kaggle/working/model_1.h5\n253/253 [==============================] - 349s 1s/step - loss: 0.1486 - accuracy: 0.0972 - val_loss: 0.1602 - val_accuracy: 0.1293\nEpoch 2/20\n253/253 [==============================] - ETA: 0s - loss: 0.1169 - accuracy: 0.1129\nEpoch 00002: val_accuracy did not improve from 0.12932\n253/253 [==============================] - 291s 1s/step - loss: 0.1169 - accuracy: 0.1129 - val_loss: 0.1155 - val_accuracy: 0.0821\nEpoch 3/20\n253/253 [==============================] - ETA: 0s - loss: 0.1111 - accuracy: 0.1128\nEpoch 00003: val_accuracy improved from 0.12932 to 0.13476, saving model to /kaggle/working/model_1.h5\n253/253 [==============================] - 287s 1s/step - loss: 0.1111 - accuracy: 0.1128 - val_loss: 0.1109 - val_accuracy: 0.1348\nEpoch 4/20\n253/253 [==============================] - ETA: 0s - loss: 0.1083 - accuracy: 0.1078\nEpoch 00004: val_accuracy did not improve from 0.13476\n253/253 [==============================] - 293s 1s/step - loss: 0.1083 - accuracy: 0.1078 - val_loss: 0.1074 - val_accuracy: 0.0920\nEpoch 5/20\n253/253 [==============================] - ETA: 0s - loss: 0.1066 - accuracy: 0.1063\nEpoch 00005: val_accuracy did not improve from 0.13476\n253/253 [==============================] - 275s 1s/step - loss: 0.1066 - accuracy: 0.1063 - val_loss: 0.1088 - val_accuracy: 0.0957\nEpoch 6/20\n253/253 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.1096\nEpoch 00006: val_accuracy did not improve from 0.13476\n253/253 [==============================] - 270s 1s/step - loss: 0.1037 - accuracy: 0.1096 - val_loss: 0.1038 - val_accuracy: 0.0835\nEpoch 7/20\n253/253 [==============================] - ETA: 0s - loss: 0.1029 - accuracy: 0.1064\nEpoch 00007: val_accuracy did not improve from 0.13476\n253/253 [==============================] - 271s 1s/step - loss: 0.1029 - accuracy: 0.1064 - val_loss: 0.1021 - val_accuracy: 0.1188\nEpoch 00007: early stopping\nFound 32383 validated image filenames.\nFound 8096 validated image filenames.\nEpoch 1/20\n253/253 [==============================] - ETA: 0s - loss: 0.1039 - accuracy: 0.1098\nEpoch 00001: val_accuracy improved from -inf to 0.10203, saving model to /kaggle/working/model_2.h5\n253/253 [==============================] - 265s 1s/step - loss: 0.1039 - accuracy: 0.1098 - val_loss: 0.1054 - val_accuracy: 0.1020\nEpoch 2/20\n253/253 [==============================] - ETA: 0s - loss: 0.1029 - accuracy: 0.1019\nEpoch 00002: val_accuracy did not improve from 0.10203\n253/253 [==============================] - 263s 1s/step - loss: 0.1029 - accuracy: 0.1019 - val_loss: 0.1037 - val_accuracy: 0.0909\nEpoch 3/20\n253/253 [==============================] - ETA: 0s - loss: 0.1009 - accuracy: 0.1096\nEpoch 00003: val_accuracy improved from 0.10203 to 0.13278, saving model to /kaggle/working/model_2.h5\n253/253 [==============================] - 263s 1s/step - loss: 0.1009 - accuracy: 0.1096 - val_loss: 0.1008 - val_accuracy: 0.1328\nEpoch 4/20\n253/253 [==============================] - ETA: 0s - loss: 0.0999 - accuracy: 0.1049\nEpoch 00004: val_accuracy did not improve from 0.13278\n253/253 [==============================] - 259s 1s/step - loss: 0.0999 - accuracy: 0.1049 - val_loss: 0.1016 - val_accuracy: 0.1108\nEpoch 5/20\n253/253 [==============================] - ETA: 0s - loss: 0.0990 - accuracy: 0.1042\nEpoch 00005: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n\nEpoch 00005: val_accuracy did not improve from 0.13278\n253/253 [==============================] - 256s 1s/step - loss: 0.0990 - accuracy: 0.1042 - val_loss: 0.1010 - val_accuracy: 0.1294\nEpoch 6/20\n253/253 [==============================] - ETA: 0s - loss: 0.0926 - accuracy: 0.1018\nEpoch 00006: val_accuracy did not improve from 0.13278\n253/253 [==============================] - 266s 1s/step - loss: 0.0926 - accuracy: 0.1018 - val_loss: 0.0944 - val_accuracy: 0.0963\nEpoch 7/20\n253/253 [==============================] - ETA: 0s - loss: 0.0910 - accuracy: 0.1066\nEpoch 00007: val_accuracy did not improve from 0.13278\n253/253 [==============================] - 258s 1s/step - loss: 0.0910 - accuracy: 0.1066 - val_loss: 0.0940 - val_accuracy: 0.0966\nEpoch 00007: early stopping\nFound 32383 validated image filenames.\nFound 8096 validated image filenames.\nEpoch 1/20\n253/253 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 0.1022\nEpoch 00001: val_accuracy improved from -inf to 0.10968, saving model to /kaggle/working/model_3.h5\n253/253 [==============================] - 261s 1s/step - loss: 0.0987 - accuracy: 0.1022 - val_loss: 0.0976 - val_accuracy: 0.1097\nEpoch 2/20\n253/253 [==============================] - ETA: 0s - loss: 0.0981 - accuracy: 0.1093\nEpoch 00002: val_accuracy improved from 0.10968 to 0.13081, saving model to /kaggle/working/model_3.h5\n253/253 [==============================] - 263s 1s/step - loss: 0.0981 - accuracy: 0.1093 - val_loss: 0.0976 - val_accuracy: 0.1308\nEpoch 3/20\n253/253 [==============================] - ETA: 0s - loss: 0.0976 - accuracy: 0.1052\nEpoch 00003: val_accuracy did not improve from 0.13081\n253/253 [==============================] - 264s 1s/step - loss: 0.0976 - accuracy: 0.1052 - val_loss: 0.0958 - val_accuracy: 0.1213\nEpoch 4/20\n253/253 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.1059\nEpoch 00004: val_accuracy did not improve from 0.13081\n253/253 [==============================] - 267s 1s/step - loss: 0.0969 - accuracy: 0.1059 - val_loss: 0.0965 - val_accuracy: 0.1051\nEpoch 5/20\n253/253 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.1023\nEpoch 00005: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n\nEpoch 00005: val_accuracy improved from 0.13081 to 0.14476, saving model to /kaggle/working/model_3.h5\n253/253 [==============================] - 280s 1s/step - loss: 0.0965 - accuracy: 0.1023 - val_loss: 0.1005 - val_accuracy: 0.1448\nEpoch 6/20\n253/253 [==============================] - ETA: 0s - loss: 0.0908 - accuracy: 0.1107\nEpoch 00006: val_accuracy did not improve from 0.14476\n253/253 [==============================] - 292s 1s/step - loss: 0.0908 - accuracy: 0.1107 - val_loss: 0.0918 - val_accuracy: 0.1199\nEpoch 7/20\n253/253 [==============================] - ETA: 0s - loss: 0.0884 - accuracy: 0.1120\nEpoch 00007: val_accuracy did not improve from 0.14476\n253/253 [==============================] - 297s 1s/step - loss: 0.0884 - accuracy: 0.1120 - val_loss: 0.0911 - val_accuracy: 0.1202\nEpoch 8/20\n253/253 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.1075\nEpoch 00008: val_accuracy did not improve from 0.14476\n253/253 [==============================] - 299s 1s/step - loss: 0.0881 - accuracy: 0.1075 - val_loss: 0.0908 - val_accuracy: 0.1249\nEpoch 9/20\n253/253 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.1041\nEpoch 00009: val_accuracy did not improve from 0.14476\n253/253 [==============================] - 300s 1s/step - loss: 0.0881 - accuracy: 0.1041 - val_loss: 0.0903 - val_accuracy: 0.1204\nEpoch 00009: early stopping\nFound 32383 validated image filenames.\nFound 8096 validated image filenames.\nEpoch 1/20\n253/253 [==============================] - ETA: 0s - loss: 0.0967 - accuracy: 0.1042\nEpoch 00001: val_accuracy improved from -inf to 0.08165, saving model to /kaggle/working/model_4.h5\n253/253 [==============================] - 284s 1s/step - loss: 0.0967 - accuracy: 0.1042 - val_loss: 0.0956 - val_accuracy: 0.0816\nEpoch 2/20\n253/253 [==============================] - ETA: 0s - loss: 0.0956 - accuracy: 0.1043\nEpoch 00002: val_accuracy improved from 0.08165 to 0.11141, saving model to /kaggle/working/model_4.h5\n253/253 [==============================] - 275s 1s/step - loss: 0.0956 - accuracy: 0.1043 - val_loss: 0.0986 - val_accuracy: 0.1114\n","name":"stdout"},{"output_type":"stream","text":"Epoch 3/20\n253/253 [==============================] - ETA: 0s - loss: 0.0957 - accuracy: 0.1003\nEpoch 00003: val_accuracy did not improve from 0.11141\n253/253 [==============================] - 270s 1s/step - loss: 0.0957 - accuracy: 0.1003 - val_loss: 0.0949 - val_accuracy: 0.1063\nEpoch 4/20\n253/253 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.0988\nEpoch 00004: val_accuracy did not improve from 0.11141\n253/253 [==============================] - 273s 1s/step - loss: 0.0941 - accuracy: 0.0988 - val_loss: 0.0988 - val_accuracy: 0.0639\nEpoch 5/20\n253/253 [==============================] - ETA: 0s - loss: 0.0939 - accuracy: 0.1015\nEpoch 00005: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n\nEpoch 00005: val_accuracy improved from 0.11141 to 0.11413, saving model to /kaggle/working/model_4.h5\n253/253 [==============================] - 273s 1s/step - loss: 0.0939 - accuracy: 0.1015 - val_loss: 0.0962 - val_accuracy: 0.1141\nEpoch 6/20\n253/253 [==============================] - ETA: 0s - loss: 0.0882 - accuracy: 0.1004\nEpoch 00006: val_accuracy did not improve from 0.11413\n253/253 [==============================] - 264s 1s/step - loss: 0.0882 - accuracy: 0.1004 - val_loss: 0.0903 - val_accuracy: 0.0944\nEpoch 7/20\n253/253 [==============================] - ETA: 0s - loss: 0.0871 - accuracy: 0.0970\nEpoch 00007: val_accuracy did not improve from 0.11413\n253/253 [==============================] - 265s 1s/step - loss: 0.0871 - accuracy: 0.0970 - val_loss: 0.0902 - val_accuracy: 0.0942\nEpoch 8/20\n253/253 [==============================] - ETA: 0s - loss: 0.0862 - accuracy: 0.1007\nEpoch 00008: val_accuracy did not improve from 0.11413\n253/253 [==============================] - 268s 1s/step - loss: 0.0862 - accuracy: 0.1007 - val_loss: 0.0910 - val_accuracy: 0.0979\nEpoch 9/20\n253/253 [==============================] - ETA: 0s - loss: 0.0861 - accuracy: 0.1027\nEpoch 00009: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n\nEpoch 00009: val_accuracy did not improve from 0.11413\n253/253 [==============================] - 269s 1s/step - loss: 0.0861 - accuracy: 0.1027 - val_loss: 0.0903 - val_accuracy: 0.0931\nEpoch 00009: early stopping\nFound 32384 validated image filenames.\nFound 8095 validated image filenames.\nEpoch 1/20\n253/253 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.1029\nEpoch 00001: val_accuracy improved from -inf to 0.09623, saving model to /kaggle/working/model_5.h5\n253/253 [==============================] - 282s 1s/step - loss: 0.0940 - accuracy: 0.1029 - val_loss: 0.0920 - val_accuracy: 0.0962\nEpoch 2/20\n253/253 [==============================] - ETA: 0s - loss: 0.0932 - accuracy: 0.0996\nEpoch 00002: val_accuracy improved from 0.09623 to 0.12897, saving model to /kaggle/working/model_5.h5\n253/253 [==============================] - 271s 1s/step - loss: 0.0932 - accuracy: 0.0996 - val_loss: 0.0930 - val_accuracy: 0.1290\nEpoch 3/20\n253/253 [==============================] - ETA: 0s - loss: 0.0929 - accuracy: 0.1085\nEpoch 00003: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n\nEpoch 00003: val_accuracy did not improve from 0.12897\n253/253 [==============================] - 273s 1s/step - loss: 0.0929 - accuracy: 0.1085 - val_loss: 0.0922 - val_accuracy: 0.1248\nEpoch 4/20\n253/253 [==============================] - ETA: 0s - loss: 0.0874 - accuracy: 0.1060\nEpoch 00004: val_accuracy did not improve from 0.12897\n253/253 [==============================] - 274s 1s/step - loss: 0.0874 - accuracy: 0.1060 - val_loss: 0.0871 - val_accuracy: 0.1045\nEpoch 5/20\n253/253 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.1058\nEpoch 00005: val_accuracy did not improve from 0.12897\n253/253 [==============================] - 263s 1s/step - loss: 0.0858 - accuracy: 0.1058 - val_loss: 0.0876 - val_accuracy: 0.0964\nEpoch 6/20\n253/253 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 0.1010\nEpoch 00006: val_accuracy did not improve from 0.12897\n253/253 [==============================] - 280s 1s/step - loss: 0.0853 - accuracy: 0.1010 - val_loss: 0.0863 - val_accuracy: 0.1059\nEpoch 00006: early stopping\n","name":"stdout"},{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"4384"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_val = predict_model(val_generator, 5)","execution_count":8,"outputs":[{"output_type":"stream","text":"64/64 [==============================] - 52s 811ms/step\n64/64 [==============================] - 52s 814ms/step\n64/64 [==============================] - 53s 825ms/step\n64/64 [==============================] - 54s 843ms/step\n64/64 [==============================] - 53s 833ms/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\npreds = np.argmax(pred_val, axis=1)\nvals = np.argmax(val_generator.labels, axis=1)\n\nprint('F2 = {}'.format(fbeta_score(vals, preds, beta=2, average='micro')))","execution_count":77,"outputs":[{"output_type":"stream","text":"F2 = 0.32390364422483015\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_original_format(df):\n    preds = []\n    for i in tqdm(range(df.shape[0]), miniters=1000):\n        a = df.iloc[[i]]\n        pred_tag=[]\n        for k in cols[1:]:\n            if(a[k][i] == 1):\n                pred_tag.append(k)\n        preds.append(' '.join(pred_tag))\n\n    df['tags'] = preds\n    df['image_name'] = df['image_name'].apply(lambda x: x.split('.')[0])\n    return df[['image_name', 'tags']]","execution_count":66,"outputs":[]},{"metadata":{"_uuid":"bf3355a2-177a-4f23-949e-adaf91ae147c","_cell_guid":"b93f9987-7293-4084-a7d8-c6512064dbfe","trusted":true},"cell_type":"code","source":"test_datagen=ImageDataGenerator(rescale=1./255.)\n\ntest1_generator=test_datagen.flow_from_dataframe(\n                                            dataframe=sample_submission, directory=f'{path}/test-jpg/',\n                                            x_col=\"image_name\", y_col=None, batch_size=8,\n                                            seed=42, shuffle=False, class_mode=None, \n                                            target_size=(input_size, input_size))\n\nresult1 = predict_model(test1_generator, 5)\nresult1 = pd.DataFrame(result1, columns=cols[1:])\nresult1[\"image_name\"]=test1_generator.filenames\nresult1 = generate_original_format(result1.copy())","execution_count":67,"outputs":[{"output_type":"stream","text":"Found 40669 validated image filenames.\n5084/5084 [==============================] - 121s 24ms/step\n5084/5084 [==============================] - 121s 24ms/step\n5084/5084 [==============================] - 120s 24ms/step\n5084/5084 [==============================] - 122s 24ms/step\n5084/5084 [==============================] - 121s 24ms/step\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 40669/40669 [00:42<00:00, 964.83it/s] \n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test2_generator=test_datagen.flow_from_dataframe(\n                                            dataframe=trad_sample_df, \n                                            directory='../input/planets-dataset/test-jpg-additional/test-jpg-additional/',\n                                            x_col=\"image_name\", y_col=None, batch_size=8,\n                                            seed=42, shuffle=False, class_mode=None, \n                                            target_size=(input_size, input_size))\n\nresult2 = predict_model(test2_generator, 5)\nresult2 = pd.DataFrame(result2, columns=cols[1:])\nresult2[\"image_name\"]=test2_generator.filenames\nresult2 = generate_original_format(result2.copy())","execution_count":70,"outputs":[{"output_type":"stream","text":"Found 20522 validated image filenames.\n2566/2566 [==============================] - 62s 24ms/step\n2566/2566 [==============================] - 60s 24ms/step\n2566/2566 [==============================] - 61s 24ms/step\n2566/2566 [==============================] - 60s 23ms/step\n2566/2566 [==============================] - 60s 23ms/step\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 20522/20522 [00:20<00:00, 987.38it/s] \n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = result1.append(result2, ignore_index=True)\nresults.to_csv(\"submission.csv\",index=False)","execution_count":72,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}