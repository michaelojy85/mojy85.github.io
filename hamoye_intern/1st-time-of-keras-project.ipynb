{"cells":[{"metadata":{"_uuid":"b213320a-08d8-4235-8dfd-1d03df2dede1","_cell_guid":"4190f27a-169b-48ce-8382-f2b966dc2d05","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd\nimport cv2, gc\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.metrics import fbeta_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.utils import shuffle\nfrom keras.models import Sequential\nfrom keras.layers import Dense, BatchNormalization, Flatten\nfrom keras.applications.vgg19 import VGG19\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow import keras\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"44de38f8-5106-4c40-a28f-6a0f7eed8fe3","_cell_guid":"235cc4b5-c0ee-4b75-b591-fc7f9843f979","trusted":true},"cell_type":"code","source":"input_size = 128\nepoch = 20\nbatch_size = 128\ninput_shape = (input_size, input_size, 3)\npath = '/kaggle/input/planets-dataset/planet/planet/'","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"18b86af5-e296-45f7-adc3-5689303f21f2","_cell_guid":"74f45f52-f940-49d0-9891-22c01f67f278","trusted":true},"cell_type":"code","source":"gc.collect()\ntrain_classes = pd.read_csv(f'{path}train_classes.csv')\ntrain_classes = shuffle(train_classes, random_state=0)\nsample_submission = pd.read_csv(f'{path}sample_submission.csv')\ntrad_sample_df = sample_submission[sample_submission.image_name.str.contains('file_')].copy()\nsample_submission = sample_submission[sample_submission.image_name.str.contains('test_')]","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s = train_classes.tags.str.split(' ').explode()\nlb = MultiLabelBinarizer()\nencoded = lb.fit_transform(s.values[:, None])\none_hot_df = pd.DataFrame(encoded.tolist(), columns=np.ravel(lb.classes_), dtype='int') \\\n                .groupby(s.index) \\\n                .sum()\none_hot_df['image_name'] = train_classes[\"image_name\"].apply(lambda fn: fn+\".jpg\")\ncols = ['image_name'] + list(np.ravel(lb.classes_))\ntrain_classes = one_hot_df[cols].copy()\ndel one_hot_df, s, encoded, lb\ntrad_sample_df['image_name'] = trad_sample_df[\"image_name\"].apply(lambda fn: fn+\".jpg\")\nsample_submission['image_name'] = sample_submission[\"image_name\"].apply(lambda fn: fn+\".jpg\")","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"d73c8b36-e9c8-4ea3-b25f-73937261f46f","_cell_guid":"54ea9955-d8b3-440b-a21d-c13b8487751f","trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True,\n                             zoom_range=0.5, rotation_range=90,\n                             rescale=1./255.)","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"3754ea10-ccc6-4191-bcd6-3edac58aeba3","_cell_guid":"a7fe1aab-779a-4f80-a34e-cd023f9018a2","trusted":true},"cell_type":"code","source":"def VGG19_Amazon_Model(input_shape=input_shape):\n    gc.collect()\n    base_model = VGG19(include_top=False, weights='imagenet',\n                       input_shape=input_shape)\n    model = Sequential()\n    model.add(BatchNormalization(input_shape=input_shape))\n    model.add(base_model)\n    model.add(Flatten())\n    model.add(Dense(17, activation='sigmoid'))\n   \n    return model\n\n\ndef return_model_name(k):\n    return '/kaggle/working/model_'+str(k)+'.h5'\n\n\ndef train_model(df, k=5):\n    gc.collect()\n    model = VGG19_Amazon_Model()\n    kf = KFold(n_splits=k, random_state=1, shuffle=True)\n    fold = 1\n\n    for train_index, val_index in kf.split(df.image_name):\n        \n        training_data = df.iloc[train_index]\n        validation_data = df.iloc[val_index]\n        \n        train_generator=datagen.flow_from_dataframe(\n                                            dataframe=training_data, directory=f'{path}/train-jpg/',\n                                            x_col=\"image_name\", y_col=cols[1:], batch_size=batch_size,\n                                            seed=42, shuffle=True, class_mode=\"raw\",\n                                            target_size=(input_size, input_size))\n        \n        val_generator=datagen.flow_from_dataframe(\n                                            dataframe=validation_data, directory=f'{path}/train-jpg/',\n                                            x_col=\"image_name\", y_col=cols[1:], batch_size=batch_size,\n                                            seed=42, shuffle=True, class_mode=\"raw\",\n                                            target_size=(input_size, input_size))\n        \n        opt = Adam(lr=0.0001)\n        model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n\n        callback = [EarlyStopping(monitor='val_accuracy', patience=4, verbose=1),\n                    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2,\n                                   cooldown=2, verbose=1),\n                    ModelCheckpoint(return_model_name(fold), monitor='val_accuracy', \n                                    verbose=1, save_best_only=True, mode='max')]\n        history = model.fit_generator(train_generator, \n                                      validation_data=val_generator,\n                                      callbacks=callback, verbose=1, epochs=epoch) \n        \n        #pred_val = model.predict_generator(val_generator, verbose=1)\n        #preds = np.array(1*(pred_val > 0.18))\n        #print(\"F BETA Score: {}\".format(fbeta_score(val_generator.labels, preds, beta=2, \n        #                                              average='samples')))\n        \n        fold += 1\n        \n    return val_generator\n\n\ndef predict_model(test_gen, k=5, batch_size=batch_size):\n    model = VGG19_Amazon_Model()\n    full_test = []\n\n    for nfold in range(1,k+1):\n        model.load_weights(filepath=return_model_name(nfold))\n        p_test = model.predict_generator(test_gen, verbose=1)\n        full_test.append(p_test)\n    \n    result = np.array(full_test[0])\n    for i in range(1, k):\n        result += np.array(full_test[i])\n    result = result / k\n    \n    return result","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"90635d17-062a-45c4-8ee6-339110ed4104","_cell_guid":"7ab5c811-b305-4c56-84c9-39487052b93c","trusted":true},"cell_type":"code","source":"val_generator = train_model(train_classes)\ngc.collect()","execution_count":7,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n80142336/80134624 [==============================] - 0s 0us/step\nFound 32383 validated image filenames.\nFound 8096 validated image filenames.\nEpoch 1/20\n253/253 [==============================] - ETA: 0s - loss: 0.1489 - accuracy: 0.0995\nEpoch 00001: val_accuracy improved from -inf to 0.05089, saving model to /kaggle/working/model_1.h5\n253/253 [==============================] - 308s 1s/step - loss: 0.1489 - accuracy: 0.0995 - val_loss: 0.1562 - val_accuracy: 0.0509\nEpoch 2/20\n253/253 [==============================] - ETA: 0s - loss: 0.1177 - accuracy: 0.1161\nEpoch 00002: val_accuracy improved from 0.05089 to 0.13463, saving model to /kaggle/working/model_1.h5\n253/253 [==============================] - 270s 1s/step - loss: 0.1177 - accuracy: 0.1161 - val_loss: 0.1158 - val_accuracy: 0.1346\nEpoch 3/20\n253/253 [==============================] - ETA: 0s - loss: 0.1118 - accuracy: 0.1095\nEpoch 00003: val_accuracy did not improve from 0.13463\n253/253 [==============================] - 269s 1s/step - loss: 0.1118 - accuracy: 0.1095 - val_loss: 0.1105 - val_accuracy: 0.0877\nEpoch 4/20\n253/253 [==============================] - ETA: 0s - loss: 0.1087 - accuracy: 0.1089\nEpoch 00004: val_accuracy did not improve from 0.13463\n253/253 [==============================] - 276s 1s/step - loss: 0.1087 - accuracy: 0.1089 - val_loss: 0.1063 - val_accuracy: 0.0958\nEpoch 5/20\n253/253 [==============================] - ETA: 0s - loss: 0.1058 - accuracy: 0.0992\nEpoch 00005: val_accuracy improved from 0.13463 to 0.13785, saving model to /kaggle/working/model_1.h5\n253/253 [==============================] - 279s 1s/step - loss: 0.1058 - accuracy: 0.0992 - val_loss: 0.1034 - val_accuracy: 0.1378\nEpoch 6/20\n253/253 [==============================] - ETA: 0s - loss: 0.1050 - accuracy: 0.1035\nEpoch 00006: val_accuracy did not improve from 0.13785\n253/253 [==============================] - 276s 1s/step - loss: 0.1050 - accuracy: 0.1035 - val_loss: 0.1024 - val_accuracy: 0.0805\nEpoch 7/20\n253/253 [==============================] - ETA: 0s - loss: 0.1034 - accuracy: 0.1054\nEpoch 00007: val_accuracy did not improve from 0.13785\n253/253 [==============================] - 277s 1s/step - loss: 0.1034 - accuracy: 0.1054 - val_loss: 0.1065 - val_accuracy: 0.0940\nEpoch 8/20\n253/253 [==============================] - ETA: 0s - loss: 0.1029 - accuracy: 0.1100\nEpoch 00008: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n\nEpoch 00008: val_accuracy did not improve from 0.13785\n253/253 [==============================] - 276s 1s/step - loss: 0.1029 - accuracy: 0.1100 - val_loss: 0.1075 - val_accuracy: 0.0929\nEpoch 9/20\n253/253 [==============================] - ETA: 0s - loss: 0.0952 - accuracy: 0.1065\nEpoch 00009: val_accuracy did not improve from 0.13785\n253/253 [==============================] - 276s 1s/step - loss: 0.0952 - accuracy: 0.1065 - val_loss: 0.0973 - val_accuracy: 0.1044\nEpoch 00009: early stopping\nFound 32383 validated image filenames.\nFound 8096 validated image filenames.\nEpoch 1/20\n253/253 [==============================] - ETA: 0s - loss: 0.1031 - accuracy: 0.1078\nEpoch 00001: val_accuracy improved from -inf to 0.14476, saving model to /kaggle/working/model_2.h5\n253/253 [==============================] - 275s 1s/step - loss: 0.1031 - accuracy: 0.1078 - val_loss: 0.1029 - val_accuracy: 0.1448\nEpoch 2/20\n253/253 [==============================] - ETA: 0s - loss: 0.1017 - accuracy: 0.1029\nEpoch 00002: val_accuracy did not improve from 0.14476\n253/253 [==============================] - 273s 1s/step - loss: 0.1017 - accuracy: 0.1029 - val_loss: 0.1011 - val_accuracy: 0.0947\nEpoch 3/20\n253/253 [==============================] - ETA: 0s - loss: 0.1007 - accuracy: 0.0963\nEpoch 00003: val_accuracy did not improve from 0.14476\n253/253 [==============================] - 272s 1s/step - loss: 0.1007 - accuracy: 0.0963 - val_loss: 0.1008 - val_accuracy: 0.1057\nEpoch 4/20\n253/253 [==============================] - ETA: 0s - loss: 0.0999 - accuracy: 0.1073\nEpoch 00004: val_accuracy did not improve from 0.14476\n253/253 [==============================] - 270s 1s/step - loss: 0.0999 - accuracy: 0.1073 - val_loss: 0.0983 - val_accuracy: 0.0970\nEpoch 5/20\n253/253 [==============================] - ETA: 0s - loss: 0.0991 - accuracy: 0.0981\nEpoch 00005: val_accuracy did not improve from 0.14476\n253/253 [==============================] - 269s 1s/step - loss: 0.0991 - accuracy: 0.0981 - val_loss: 0.1030 - val_accuracy: 0.0928\nEpoch 00005: early stopping\nFound 32383 validated image filenames.\nFound 8096 validated image filenames.\nEpoch 1/20\n253/253 [==============================] - ETA: 0s - loss: 0.0998 - accuracy: 0.1001\nEpoch 00001: val_accuracy improved from -inf to 0.12228, saving model to /kaggle/working/model_3.h5\n253/253 [==============================] - 271s 1s/step - loss: 0.0998 - accuracy: 0.1001 - val_loss: 0.0968 - val_accuracy: 0.1223\nEpoch 2/20\n253/253 [==============================] - ETA: 0s - loss: 0.0981 - accuracy: 0.0999\nEpoch 00002: val_accuracy did not improve from 0.12228\n253/253 [==============================] - 276s 1s/step - loss: 0.0981 - accuracy: 0.0999 - val_loss: 0.0973 - val_accuracy: 0.1036\nEpoch 3/20\n253/253 [==============================] - ETA: 0s - loss: 0.0975 - accuracy: 0.0952\nEpoch 00003: val_accuracy did not improve from 0.12228\n253/253 [==============================] - 275s 1s/step - loss: 0.0975 - accuracy: 0.0952 - val_loss: 0.0964 - val_accuracy: 0.1028\nEpoch 4/20\n253/253 [==============================] - ETA: 0s - loss: 0.0971 - accuracy: 0.1014\nEpoch 00004: val_accuracy did not improve from 0.12228\n253/253 [==============================] - 277s 1s/step - loss: 0.0971 - accuracy: 0.1014 - val_loss: 0.0961 - val_accuracy: 0.1070\nEpoch 5/20\n253/253 [==============================] - ETA: 0s - loss: 0.0956 - accuracy: 0.0909\nEpoch 00005: val_accuracy did not improve from 0.12228\n253/253 [==============================] - 273s 1s/step - loss: 0.0956 - accuracy: 0.0909 - val_loss: 0.0978 - val_accuracy: 0.0763\nEpoch 00005: early stopping\nFound 32383 validated image filenames.\nFound 8096 validated image filenames.\nEpoch 1/20\n253/253 [==============================] - ETA: 0s - loss: 0.0959 - accuracy: 0.1039\nEpoch 00001: val_accuracy improved from -inf to 0.10993, saving model to /kaggle/working/model_4.h5\n253/253 [==============================] - 267s 1s/step - loss: 0.0959 - accuracy: 0.1039 - val_loss: 0.0957 - val_accuracy: 0.1099\nEpoch 2/20\n253/253 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.0963\nEpoch 00002: val_accuracy did not improve from 0.10993\n253/253 [==============================] - 267s 1s/step - loss: 0.0954 - accuracy: 0.0963 - val_loss: 0.0975 - val_accuracy: 0.0828\nEpoch 3/20\n253/253 [==============================] - ETA: 0s - loss: 0.0956 - accuracy: 0.0998\nEpoch 00003: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n\nEpoch 00003: val_accuracy did not improve from 0.10993\n253/253 [==============================] - 271s 1s/step - loss: 0.0956 - accuracy: 0.0998 - val_loss: 0.0967 - val_accuracy: 0.0847\nEpoch 4/20\n253/253 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 0.0972\nEpoch 00004: val_accuracy did not improve from 0.10993\n253/253 [==============================] - 272s 1s/step - loss: 0.0896 - accuracy: 0.0972 - val_loss: 0.0919 - val_accuracy: 0.0876\nEpoch 5/20\n253/253 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.0952\nEpoch 00005: val_accuracy did not improve from 0.10993\n253/253 [==============================] - 271s 1s/step - loss: 0.0878 - accuracy: 0.0952 - val_loss: 0.0901 - val_accuracy: 0.1000\nEpoch 00005: early stopping\nFound 32384 validated image filenames.\nFound 8095 validated image filenames.\nEpoch 1/20\n253/253 [==============================] - ETA: 0s - loss: 0.0951 - accuracy: 0.0974\nEpoch 00001: val_accuracy improved from -inf to 0.08833, saving model to /kaggle/working/model_5.h5\n253/253 [==============================] - 270s 1s/step - loss: 0.0951 - accuracy: 0.0974 - val_loss: 0.0930 - val_accuracy: 0.0883\n","name":"stdout"},{"output_type":"stream","text":"Epoch 2/20\n253/253 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 0.1019\nEpoch 00002: val_accuracy improved from 0.08833 to 0.11217, saving model to /kaggle/working/model_5.h5\n253/253 [==============================] - 267s 1s/step - loss: 0.0950 - accuracy: 0.1019 - val_loss: 0.0929 - val_accuracy: 0.1122\nEpoch 3/20\n253/253 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.0969\nEpoch 00003: val_accuracy did not improve from 0.11217\n253/253 [==============================] - 269s 1s/step - loss: 0.0941 - accuracy: 0.0969 - val_loss: 0.0977 - val_accuracy: 0.0934\nEpoch 4/20\n253/253 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.0938\nEpoch 00004: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n\nEpoch 00004: val_accuracy did not improve from 0.11217\n253/253 [==============================] - 266s 1s/step - loss: 0.0945 - accuracy: 0.0938 - val_loss: 0.0948 - val_accuracy: 0.1012\nEpoch 5/20\n253/253 [==============================] - ETA: 0s - loss: 0.0883 - accuracy: 0.1033\nEpoch 00005: val_accuracy did not improve from 0.11217\n253/253 [==============================] - 267s 1s/step - loss: 0.0883 - accuracy: 0.1033 - val_loss: 0.0889 - val_accuracy: 0.0952\nEpoch 6/20\n253/253 [==============================] - ETA: 0s - loss: 0.0868 - accuracy: 0.0995\nEpoch 00006: val_accuracy did not improve from 0.11217\n253/253 [==============================] - 266s 1s/step - loss: 0.0868 - accuracy: 0.0995 - val_loss: 0.0874 - val_accuracy: 0.0907\nEpoch 00006: early stopping\n","name":"stdout"},{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"4384"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_val = predict_model(val_generator, 5)        \n#pred_val = (pred_val > 0.18)\n#preds = pred_val.astype(int)\n#vals = np.array(val_generator.labels, np.int8)\n#print('F2 = {}'.format(fbeta_score(vals, np.array(pred_val) > 0.18, beta=2, average='samples')))","execution_count":42,"outputs":[{"output_type":"stream","text":"64/64 [==============================] - 48s 754ms/step\n64/64 [==============================] - 48s 751ms/step\n64/64 [==============================] - 48s 746ms/step\n64/64 [==============================] - 47s 735ms/step\n64/64 [==============================] - 48s 742ms/step\n","name":"stdout"}]},{"metadata":{"_uuid":"bf3355a2-177a-4f23-949e-adaf91ae147c","_cell_guid":"b93f9987-7293-4084-a7d8-c6512064dbfe","trusted":true},"cell_type":"code","source":"test_datagen=ImageDataGenerator(rescale=1./255.)\n\ntest2_generator=test_datagen.flow_from_dataframe(\n                                            dataframe=sample_submission, directory=f'{path}/test-jpg/',\n                                            x_col=\"image_name\", y_col=None, batch_size=16,\n                                            seed=42, shuffle=False, class_mode=None, \n                                            target_size=(input_size, input_size))","execution_count":55,"outputs":[{"output_type":"stream","text":"Found 40669 validated image filenames.\n","name":"stdout"}]},{"metadata":{"_uuid":"d92906ff-51a7-48c6-a3d9-01ae76ee0088","_cell_guid":"f8eece2b-126e-4824-a6d8-a75a55229c3f","trusted":true},"cell_type":"code","source":"pred_test = predict_model(test1_generator, 5)\npred_bool = (pred_test > 0.18)\nresult1 = pred_bool.astype(int)\nresult1 = pd.DataFrame(result1, columns=cols[1:])","execution_count":58,"outputs":[{"output_type":"stream","text":"2542/2542 [==============================] - 117s 46ms/step\n2542/2542 [==============================] - 112s 44ms/step\n2542/2542 [==============================] - 112s 44ms/step\n2542/2542 [==============================] - 111s 44ms/step\n2542/2542 [==============================] - 111s 44ms/step\n","name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"Shape of passed values is (40669, 17), indices imply (40669, 18)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1661\u001b[0m                 blocks = [\n\u001b[0;32m-> 1662\u001b[0;31m                     \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1663\u001b[0m                 ]\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[1;32m   2713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2714\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    129\u001b[0m             raise ValueError(\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0;34mf\"Wrong number of items passed {len(self.values)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;34mf\"placement implies {len(self.mgr_locs)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 17, placement implies 18","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-58-21e23fa3f5c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpred_bool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred_test\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_bool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#To get the same column order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mblock_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1670\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"values\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1672\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Shape of passed values is (40669, 17), indices imply (40669, 18)"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test2_generator=test_datagen.flow_from_dataframe(\n                                            dataframe=trad_sample_df, \n                                            directory='../input/planets-dataset/test-jpg-additional/test-jpg-additional/',\n                                            x_col=\"image_name\", y_col=None, batch_size=16,\n                                            seed=42, shuffle=False, class_mode=None, \n                                            target_size=(input_size, input_size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_test = predict_model(test2_generator, 5)\npred_bool = (pred_test > 0.18)\nresult2 = pred_bool.astype(int)\nresult2 = pd.DataFrame(result2, columns=cols[1:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = result1.append(result2)\nresults[\"image_name\"]=test_generator.filenames\nresults = results[cols] #To get the same column order\nresults.to_csv(\"submission.csv\",index=False)","execution_count":60,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}